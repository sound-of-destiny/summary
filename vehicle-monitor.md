##### 自我介绍

- 你好，我叫舒冲冲，本科和研究生都就读于山东大学，主要技术栈是java，平常一直在linux平台上开发。另外也熟悉c/c++和go语言。最近的一个项目是一个汽车运输公司委托我们帮他们做一个满足交通部jt808, jt1078和苏标ADAS协议的一个平台来送去交通部过检。项目主要包括jt808服务器，jt809服务器，jt1078服务器和web端四个主要部分。我主要负责jt808服务器，jt1078服务器和部分相关的后台前端的开发。后面说以下项目难点和待完成的部分，然后说明自己学到的东西，没被打住就接着说下面的项目 :
- 主要是为一家阿根廷超市管理系统写商品搜索模块 (主要是输入有关商品的任何信息就可以搜索到商品)，日志分析模块 (主要是用来分析客户的使用率，登录地点，登录时间，改价操作)和参考价计算模块(主要是通过各个超市的改价操作来确定商品的最近价格，然后根据众多超市的价格来给出一个相对合理的价格)。
- 主要是为山东大学研究生信息管理系统编写了出国管理模块(主要是利用工作流引擎来实现学生出国申请的导师审核、二级学院审核(可能有)、学院审核、研究生院审核，出国状态外加正常归国、提前归国、延期归国等一系列审核操作) 和成绩单打印模块(主要负责研究生中英文成绩单的打印)

##### 语言并不重要，而且现在java和c++在语法和功能上已经非常相似了

##### 所有项目都收获很多，因为每个都是不同方面的项目

##### 项目难点 :

- 对自定义协议的处理 : 多个车辆终端的多线程处理，特别是终端发送图片过来的时候，因为图片比较大，进行了分片，而 netty 默认是一个线程处理一个特定的连接，所以必须在处理过程中开辟新的线程来处理图片
- 对G726音频的编解码 : G726这种格式十分少见，在查询了介绍 RTP 的文档 RFC3551 后才了解到它分为40K, 32K, 24K, 16K四个等级采样位数分别为５, 4, 3, 2，采样率都是8000，且每秒20个数据包。首先需要将其转化为 PCM 格式，然后再转化为 AAC 格式。但最为困难的是将它和 h.264 格式的视屏画面进行音画同步。由于一开始项目使用 java 开发，因此使用的是javacv 中的 FFmpeg 来处理。但是由于java 中的 FFmpeg 不好控制，而且设备发送过来的每帧的时间戳也并不准确，因此必须分析帧的类型 : I帧、P帧、B帧和 PTS 帧(用于度量解码后的视频帧什么时候被显示出来)、DTS 帧(主要是标识读入内存中的 bit 流在什么时候开始送入解码器中进行解码) 来确定时间输出音频帧，找到了解析G726的 c 程序，现在因为这个项目中的音频不是很重要，所以目前还是在使用 java 的服务器，后面会改造成 c++ 的。
- 实现网页端和车辆终端的语音对讲 : 使用的是 WebRTC 提供的接口来获取网页端的音频，然后利用Recordjs来保存音频数据，通过 websocket 的二进制模式来传输音频数据到服务端经过编解码送到终端。而终端的音频数据同样通过编解码后，利用 websocket 传输到 web 端播放，目前 bug 比较多，后面会改进
- 文件服务器的信令端口和文件传输端口被设置成一个端口，无法完美的分辨出到底是那种数据

##### 通过项目学习到了什么

- 熟悉了网络应用的开发
- 熟悉了音视频编解码方面开发的知识
- 熟悉了多线程编程的知识
- 熟悉了多个服务间的信息传输，RPC 方面的知识
- 熟悉了服务的容器化部署方面的知识
- 熟悉了技术的选型和调整，和对多种常用的应用和框架的了解

##### 参考价计算


- GMM 高斯混合模型
- 由于 ~~阿根廷首都布宜诺斯艾利斯分为三大区域 : 核心区、中间区和偏远区，他们的价格可能总体上可能呈现出 : 核心区 > 中间区 > 偏远区~~ 客户反映价格会呈驼峰型可能会有多个峰值 (利用 python 的 matplotlib 库实现了可视化的观察)。因此采用 EM 算法的迭代求解通过**最大似然估计**进行参数估计 (最大似然估计就是让概率分布参数最符合观察到的样本)，然后利用利用GMM估计各个区域的比例和中位数。最后用 k-means 算法做了个对比(k-means 使用的是曼哈顿距离)，来最终确定价格 (通过对各种参数的调节)。

- **优化过程**

  - python 编写，计算速度非常慢

  - java 编写，速度达到 3 小时以内

  - 多线程优化，速度达到 1 小时以内

  - 通过将上个星期的计算结果保存起来，使以后每个星期只用计算当前星期的数据即可，速度基本满足要求

  - 利用 java streamAPI 大大简化了编码过程

    ```java
    Map<String, Map<Integer, Double>> result = new HashMap<>();
            Map<String, List<Codigo>> map = list.parallelStream().collect(Collectors.groupingBy(Codigo::getCodigoId));
            map.forEach((codigo, codigos) -> {
                Map<Integer, Double> innermap = new HashMap<>();
                Map<Integer, List<Codigo>> map2 = codigos.parallelStream().collect(Collectors.groupingBy(Codigo::getMerchant));
                map2.forEach((mer, mers) -> {
                    Optional<Codigo> c = mers.parallelStream().max(Comparator.comparingInt(Codigo::getTime));
                    c.ifPresent(c1 -> innermap.put(mer, c1.getPrice()));
                });
                result.put(codigo, innermap);
            });
    
    ```

  - 利用**文件映射** (FileChannel + MappedByteBuffer) 加快了文件的读取速度 (因为数据是按文件存的)

  - 调大 --XX:Xmx 来解决堆内存溢出的问题

- EM算法 : 当有部分数据缺失或者无法观察到时，EM算法提供了一个高效的迭代程序用来计算这些数据的最大似然估计。在每一步迭代分为两个步骤：期望（Expectation）步骤和最大化（Maximization）步骤，因此称为EM算法。EM算法通过搜寻使全部数据的似然函数Log(L(Z; h))的期望值最大来寻找极大似然估计

- 对于由参数未知的K个高斯混合模型生成的数据集，利用EM算法可以对这K个高斯分布进行参数估计，并且可以知道两个模型的各自比重。因此还可以用来聚类

- EM算法包括两个过程：

  - E 已知参数 lamda，求概率（期望）P
  - M 根据算出的P，求新的lamda以使出现P的概率最大

##### 搜索引擎

- **优化过程**

  - 使用 solr : 项目太小，完全用不上，而且使得架构变得复杂

  - 使用 solr 的内核 lucene 提供的 API 

    - Directory : 因为数据量很小 : RAMDirectory (mainDirectory, spellDirectory, suggestDirectory)
    - IndexWriter : 用来处理索引的对象
      - Term : 最小搜索单元，由两个元素组成 : 词语的内容和文本所在的域
      - Document : 一条记录
    - Analyzer : 用来分析特定语言的语法，用来分词。中文IK分词器等，这里通用
    - SpellChecker : 拼写纠错 spellChecker.suggestSimilar
    - LuceneSpellCheck 检索数据中是否存在编辑距离与查询单词相近的单词以帮助客户纠正拼写错误
    - AnalyzingInfixSuggester : 建议器

    - TokenStream 用某种规则 (空格) 分割查询的单词，ts.getAttribute(CharTermAttribute.class);　ts.incrementToken()

    - IndexSearcher, QueryParser, Query, TopDocs, TermQuery

- lucene : 主要是想从商品描述中也可以搜索到商品

  - Lucene中包含了四种基本数据类型，分别是：

    - Index：索引，由很多的Document组成
    - Document：由很多的Field组成，是Index和Search的最小单位
    - Field：由很多的Term组成，包括Field Name和Field Value
    - Term：由很多的字节组成。一般将Text类型的Field Value分词之后的每个最小单元叫做Term

  - 在lucene中，读写路径是分离的。写入的时候创建一个IndexWriter，而读的时候会创建一个IndexSearcher

  - Lucene 查询过程
  
    - 在lucene中查询是基于segment。每个segment可以看做是一个独立的subindex，在建立索引的过程中，lucene会不断的flush内存中的数据持久化形成新的segment。多个segment也会不断的被merge成一个大的segment，在老的segment还有查询在读取的时候，不会被删除，没有被读取且被merge的segement会被删除。这个过程类似于LSM数据库的merge过程。下面我们主要看在一个segment内部如何实现高效的查询
    
  - 建立倒排链 (根据docid来判断是哪个Document，在被查询的Field的各个term中列出存在此term的docid)，所以倒排本质上就是基于term的反向列表
    
    - 如果term非常多，如何快速拿到这个倒排链呢？在lucene里面就引入了term dictonary的概念，也就是term的字典。term字典里我们可以按照term进行排序，那么用一个二分查找就可以定为这个term所在的地址。这样的复杂度是logN，在term很多，内存放不下的时候，效率还是需要进一步提升。可以用一个hashmap，当有一个term进入，hash继续查找倒排链。这里hashmap的方式可以看做是term dictionary的一个index。 从lucene4开始，为了方便实现rangequery或者前缀，后缀等复杂的查询语句，lucene使用FST数据结构来存储term字典，下面就详细介绍下FST的存储结构
    
  - **FST : term字典的存储结构 利用 Trie 树**
    
    - FST在单term查询上可能相比hashmap并没有明显优势，甚至会慢一些。但是在范围，前缀搜索以及压缩率上都有明显的优势
      - 在通过FST定位到倒排链后，有一件事情需要做，就是倒排链的合并。因为查询条件可能不止一个，例如上面我们想找name="alan" and age="18"的列表。lucene是如何实现倒排链的合并呢。这里就需要看一下倒排链存储的数据结构
    
  - **SkipList : 倒排链的存储结构**
    
      - 元素排序的，对应到我们的倒排链，lucene是按照docid进行排序，从小到大
    - 跳跃有一个固定的间隔，这个是需要建立SkipList的时候指定好
      - SkipList的层次，这个是指整个SkipList有几层
    
  - Term dict index (FST Trie)  --->  Term dict  --->  invert index (倒排索引 SkipList)
    - 倒排合并    termA  termB  termC
    
      1. 在termA开始遍历，得到第一个元素docid = 1
    2. Set currentDocId = 1
      3. 在termB中 search(currentDocId) = 1 (返回大于等于currentDocId的一个doc)
       - 如果currentDocId ==1，继续
         - 如果currentDocId 和返回的不相等，执行2，然后继续
    4. 到termC后依然符合，返回结果
      5. currentDocId = termC的nextItem
      6. 然后继续步骤3 依次循环。直到某个倒排链到末尾
    - 整个合并步骤我可以发现，如果某个链很短，会大幅减少比对次数，并且由于SkipList结构的存在，在某个倒排中定位某个docid的速度会比较快不需要一个个遍历。可以很快的返回最终的结果。从倒排的定位，查询，合并整个流程组成了lucene的查询过程，和传统数据库的索引相比，lucene合并过程中的优化减少了读取数据的IO，倒排合并的灵活性也解决了传统索引较难支持多条件查询的问题
    
  - **BKDTree**
  
      - 在lucene中如果想做范围查找，根据上面的FST模型可以看出来，需要遍历FST找到包含这个range的一个点然后进入对应的倒排链，然后进行求并集操作。但是如果是数值类型，比如是浮点数，那么潜在的term可能会非常多，这样查询起来效率会很低。所以**为了支持高效的数值类或者多维度查询**，lucene引入类BKDTree。BKDTree是基于KDTree，对数据进行按照维度划分建立一棵二叉树确保树两边节点数目平衡。在一维的场景下，KDTree就会退化成一个二叉搜索树，在二叉搜索树中如果我们想查找一个区间，logN的复杂度就会访问到叶子结点得到对应的倒排链
      - 如果是多维，kdtree的建立流程会发生一些变化。比如我们以二维为例，建立过程如下 :
        - 确定切分维度，这里维度的选取顺序是数据在这个维度方法最大的维度优先。一个直接的理解就是，数据分散越开的维度，我们优先切分
        - 切分点的选这个维度最中间的点
        - 递归进行步骤1，2，我们可以设置一个阈值，点的数目少于多少后就不再切分，直到所有的点都切分好停止
        - BKDTree是KDTree的变种，因为可以看出来，KDTree如果有新的节点加入，或者节点修改起来，消耗还是比较大。类似于LSM的merge思路，BKD也是多个KDTREE，然后持续merge最终合并成一个。不过我们可以看到如果你某个term类型使用了BKDTree的索引类型，那么在和普通倒排链merge的时候就没那么高效了所以这里要做一个平衡，一种思路是把另一类term也作为一个维度加入BKDTree索引中
  
  - 如何实现返回结果进行排序聚合 : 在lucene4之前需要把结果全部拿到再读取原文进行排序，这样效率较低，还比较占用内存，为了加速lucene实现了fieldcache，把读过的field放进内存中。这样可以减少重复的IO，但是也会带来新的问题，就是占用较多内存。新版本的lucene中引入了DocValues，DocValues是一个基于docid的列式存储。当我们拿到一系列的docid后，进行排序就可以使用这个列式存储，结合一个堆排序进行。当然额外的列式存储会占用额外的空间，lucene在建索引的时候可以自行选择是否需要DocValue存储和哪些字段需要存储
  
  - Lucene的代码目录结构
  
      - analysis模块主要负责词法分析及语言处理而形成Term
      - codecs模块主要负责之前提到的一些数据结构的实现，和一些编码压缩算法。包括skiplist，docvalue等
      - document模块主要包括了lucene各类数据类型的定义实现
      - index模块主要负责索引的创建，里面有IndexWriter
      - store模块主要负责索引的读写
      - search模块主要负责对索引的搜索
      - geo模块主要为geo查询相关的类实现
      - util模块是bkd，fst等数据结构实现
  
  - lucene 默认评分公式
  
      - 什么是文档得分？它是一个刻画文档与查询匹配程度的参数
      - TF/IDF（词频/逆文档频率）算法以及它是如何影响文档查询结果的
        - 公式融合了布尔检索模型和向量空间检索模型
        - 评分公式是一个关于查询q和文档d的函数，正如我们之前提到的一样。有两个因子并不直接依赖查询词项，它们是coord和queryNorm，这两个因子与查询词项的一个求和公式相乘
        - 逆文档频率 : 越罕见的词项被匹配上，文档得分越高。Lucene认为包含独特单词的文档比包含常见单词的文档更重要
        - 词频 : 文档字段越短（包含更少的词项），文档得分越高。通常，Lucene更加重视较短的文档，因为这些短文档更有可能和我们查询的主题高度吻合
        - 文档权重，字段权重 : 权重越高（不论是索引期或是查询期赋予的权重值），文档得分越高。因为更高的权重意味着特定数据（文档、词项、短语等）具有更高的重要性
      - 为了计算文档得分，我们需要考虑以下这些因子 :
        - 文档权重（document boost）：索引期赋予某个文档的权重值
        - 字段权重（field boost）：查询期赋予某个字段的权重值
        - 逆文档频率（inverse document frequency）：一个基于词项的因子，用来告诉评分公式该词项有多么罕见。逆文档频率越高，词项就越罕见。评分公式利用该因子，为包含罕见词项的文档加权
        - 长度范数（Length norm）：每字段的基于词项个数的归一化因子（在索引期被计算并存储在索引中）。一个字段包含的词项数越多，该因子的权重越低，这意味着Apache Lucene评分公式更“喜欢”包含更少词项的字段
        - 词频（Term frequency）：一个基于词项的因子，用来表示一个词项在某个文档中出现了多少次。词频越高，文档得分越高
        - 协调因子（coord）：基于文档中词项个数的协调因子，一个文档命中了查询中的词项越多，得分越高
        - 查询范数(Query norm)：一个基于查询的归一化因子，它等于查询中词项的权重平方和。查询范数使不同查询的得分能互相比较，尽管这种比较通常是困难和不可行的
  
  - 准实时、更新即事务日志
  
      - 一次提交并不足以保证新索引的数据能被搜索到，这是因为Lucene使用了一个叫作Searcher的抽象类来执行索引的读取。如果索引更新提交了，但Searcher实例并没有重新打开，那么它觉察不到新索引段的加入。Searcher重新打开的过程叫作刷新（refresh）。出于性能考虑，Lucene推迟了耗时的刷新，因此它不会在每次新增一个文档（或批量增加文档）的时候刷新，但Searcher会每秒刷新一次。这种刷新已经非常频繁了，然而有很多应用却需要更快的刷新频率。如果碰到这种状况，要么使用其他技术，要么审视需求是否合理
      - Apache Lucene能保证索引的一致性，这非常棒，但是这并不能保证当往索引中写数据失败时不会损失数据（如磁盘空间不足、设备损坏，或没有足够的文件句柄供索引文件使用）。另外，频繁提交操作会导致严重的性能问题（因为每提交一次就会触发一个索引段的创建操作，同时也可能触发索引段的合并）。ElasticSearch通过使用事务日志（transaction log）来解决这些问题，它能保存所有的未提交的事务，而ElasticSearch会不时创建一个新的日志文件用于记录每个事务的后续操作。当有错误发生时，就会检查事务日志，必要时会再次执行某些操作，以确保没有丢失任何更改信息。而且，事务日志的相关操作都是自动完成的，用户并不会意识到某个特定时刻触发的更新提交。事务日志中的信息与存储介质之间的同步（同时清空事务日志）称为事务日志刷新（flushing）。
      - 请注意事务日志刷新与Searcher刷新的区别。大多数情况下，Searcher刷新是你所期望的，即搜索到最新的文档。而事务日志刷新用来确保数据正确写入了索引并清空了事务日志
      - 事务日志给我们带来一个免费的特性 : 实时读取（real-time GET），该功能让返回文档各种版本（包括未提交版本）成为可能。实时读取操作从索引中读取数据时，会先检查事务日志中是否有可用的新版本。如果近期索引没有与事务日志同步，那么索引中的数据将会被忽略，事务日志中最新版本的文档将会被返回

##### 策略模式 : 定义一系列算法，将每一个算法封装起来，并让它们可以相互替换。策略模式让算法独立于使用它的客户而变化，也称为政策模式(Policy)。

- 完成一项任务，往往可以有多种不同的方式，每一种方式称为一个策略，我们可以根据环境或者条件的不同选择不同的策略来完成该项任务
- 在软件开发中也常常遇到类似的情况，实现某一个功能有多个途径，此时可以使用一种设计模式来使得系统可以灵活地选择解决途径，也能够方便地增加新的解决途径
- 可以定义一些独立的类来封装不同的算法，每一个类封装一个具体的算法，在这里，每一个封装算法的类我们都可以称之为策略(Strategy)，为了保证这些策略的一致性，一般会用一个抽象的策略类来做算法的定义，而具体每种算法则对应于一个具体策略类

##### 观察者模式 : 

- 优点
  - 观察者模式在被观察者和观察者之间建立一个抽象的耦合。被观察者角色所知道的只是一个具体观察者列表，每一个具体观察者都符合一个抽象观察者的接口。被观察者并不认识任何一个具体观察者，它只知道它们都有一个共同的接口
  - 由于被观察者和观察者没有紧密地耦合在一起，因此它们可以属于不同的抽象化层次。如果被观察者和观察者都被扔到一起，那么这个对象必然跨越抽象化和具体化层次
  - 观察者模式支持广播通讯。被观察者会向所有的登记过的观察者发出通知
- 缺点
  - 如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间
  - 如果在被观察者之间有循环依赖的话，被观察者会触发它们之间进行循环调用，导致系统崩溃。在使用观察者模式是要特别注意这一点
  - 如果对观察者的通知是通过另外的线程进行异步投递的话，系统必须保证投递是以自恰的方式进行的
  - 虽然观察者模式可以随时使观察者知道所观察的对象发生了变化，但是观察者模式没有相应的机制使观察者知道所观察的对象是怎么发生变化的
- 应用场景
  - 对一个对象状态的更新，需要其他对象同步更新，而且其他对象的数量动态可变
  - 对象仅需要将自己的更新通知给其他对象而不需要知道其他对象的细节



##### 为什么使用 mongodb 

- 架构简单
- 没有复杂的连接
- 深度查询能力 MongoDB支持动态查询

- 支持内嵌对象和数组对象
- 后面可能会用 HBase 存储历史数据
- 不需要转化/映射应用对象到数据库对象
- 使用内存作为存储工作区,以便更快的存取数据
- 因为 `query` 简单了，少了许多消耗资源的 `join` 操作，速度自然会上去
- 非常适合实时的插入，更新与查询，并具备网站实时数据存储所需的复制及高度伸缩性。
- 易于扩展

##### mongoDB

- MongoDB用c++编写的

- 非关系型数据库的显著特点是不使用SQL作为查询语言，数据存储不需要特定的表格模式
- 分片是将数据水平切分到不同的物理节点。当应用数据越来越大的时候，数据量也会越来越大。当数据量增长时，单台机器有可能无法存储数据或可接受的读取写入吞吐量。利用分片技术可以添加更多的机器来应对数据量增加以及读写操作的要求

##### 为什么使用 MQ 

- 使得前端不用一直向后台请求位置信息，实现一定的实时性
- 解耦 : 开始使用的是 WebSocket，使得浏览器与 jt808 服务器耦合度太高
- 分摊 jt808 服务器的压力 : 需要向多个浏览器发送位置信息，占用了 jt808 的带宽和处理器时间
- 异步 : 分离数据的获取与处理，易于后面数据的处理，使得 jt808 不用自己存储原始数据。将消息发送到消息队列之后立即返回，之后这个操作会被异步处理
- 如果设备大于一定数量后，jt808 可能会集群部署，用 MQ 可以统一数据的处理
- ~~不用考虑消息被重复消费 (消息被消费时的幂等性)~~ 先根据 timeStamp 查一下，如果数据存在，就不插入了

##### 为什么使用 RabbitMQ 

- 使用简单，成熟的 API 文档，良好的管理界面
- 使用 erlang 编写，性能很好
- 支持持久化，在消费者下线的情况下，生产的消息会丢失
- 支持 Stomp

##### 如何保证消息队列是高可用的

RabbitMQ 集群

##### 如何保证消费的可靠性传输

- 生产者丢数据 : RabbitMQ提供transaction和confirm模式来确保生产者不丢消息

  transaction机制就是说，发送消息前，开启事物(channel.txSelect())，然后发送消息，如果发送过程中出现什么异常，事物就会回滚(channel.txRollback())，如果发送成功则提交事物(channel.txCommit())

- 消息队列丢数据 : 处理消息队列丢数据的情况，一般是开启持久化磁盘的配置

  - 将queue的持久化标识durable设置为true,则代表是一个持久的队列
  - 发送消息的时候将 deliveryMode = 2

- 消费者丢数据 : 消费者丢数据一般是因为采用了自动确认消息模式。这种模式下，消费者会自动确认收到信息。这时rahbitMQ会立即将消息删除，这种情况下如果消费者出现异常而没能处理该消息，就会丢失该消息
  至于解决方案，采用手动确认消息即可 

##### 为什么使用缓存

- 缓存性能高
- 缓存雪崩 : 缓存失效，流量击垮数据库
  - 事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃
  - 事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 MySQL 被打死
  - 事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据
- 服务降级 : 一个非核心的功能异常最终导致了整个系统的不可用为了了避免这种小功能搞垮大系统的情况发生
  - 降级按照是否自动化可分为：自动开关降级和人工开关降级
    - 超时降级 : 当访问的数据库/http服务/远程调用响应慢或者长时间响应慢，且该服务不是核心服务的话可以在超时后自动降级
    - 统计失败次数降级 : 有时候依赖一些不稳定的API，比如调用外部机票服务，当失败调用次数达到一定阀值自动降级；然后通过异步线程去探测服务是否恢复了，则取消降级
    - 故障降级 : 比如要调用的远程服务挂掉了（网络故障、DNS故障、http服务返回错误的状态码、rpc服务抛出异常），则可以直接降级
    - 限流降级 : 当我们去秒杀或者抢购一些限购商品时，此时可能会因为访问量太大而导致系统崩溃，此时开发者会使用限流来进行限制访问量，当达到限流阀值，后续请求会被降级
  - 降级按照功能可分为：读服务降级、写服务降级
    - 动态化降级为静态化：比如平时网站可以走动态化渲染商品详情页，但是到了大促来临之际可以将其切换为静态化来减少对核心资源的占用，而且可以提升性能
    - 写服务在大多数场景下是不可降级的，不过可以通过一些迂回战术来解决问题。比如将同步操作转换为异步操作，或者限制写的量/比例
  - 降级按照处于的系统层次可分为：多级降级
- 限流组件 : 可以设置每秒的请求，未通过的请求走降级，可以返回一些默认的值，或友情提示，或空白
  - 数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过
  - 只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的
  - 只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来一次
- 常见的限流算法有：令牌桶、漏桶。计数器也可以进行粗暴限流实现
  - 令牌桶算法 : 令牌桶算法是一个存放固定容量令牌的桶，按照固定速率往桶里添加令牌 Semaphore
  - 漏桶算法 : 漏桶作为计量工具（The Leaky Bucket Algorithm as a Meter）时，可以用于流量整形（Traffic Shaping）和流量控制（TrafficPolicing）
- cache aside pattern : 
  - 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应
  - 更新的时候，**先更新数据库，然后再删除缓存**/**先删除缓存，然后再更新数据库**
  - 更新数据的时候，根据**数据的唯一标识**，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个 jvm 内部队列中

##### 为什么要用 Redis

- 纯内存操作

- 单线程

- 高效的数据结构

  - 特殊的字符串结构 SDS { int len; int free; char buf[] } 二进制安全
  - rehash，渐进式 rehash分多次完成 rehash 操作
  - **跳跃表 zskipList 是有序集合 Zset 的底层结构**
  - 压缩列表 zipList 是 Redis 为节约内存而开发的，是列表键和字典键的底层实现之一
  - String : int、raw，List : zipList、linkedList，Hash : zipList、hashtable，Set : intSet、hashtable，Zset : ziplist、zskiplist

- Redis 会将每一个设置了 expire 的键存储在一个独立的字典中，Redis 默认每秒进行十次过期扫描，过期扫描不会扫描所有过期字典中的 key，而是采用了一种简单的贪心策略

- redis 事务的 CAS : **多客户端同时并发写**一个 key

  - 可以基于 zookeeper 实现分布式锁
  - 写入缓存的数据，都是从 mysql 里查出来的，都得写入 mysql 中，写入 mysql 中的时候必须保存一个时间戳，从 mysql 查出来的时候，时间戳也查出来

- redis cluster 介绍

  - 自动将数据进行分片，每个 master 上放一部分数据
  - 供内置的高可用支持，部分 master 不可用时，还是可以继续工作的
  - redis cluster 节点间采用 gossip 协议进行通信，每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，gossip 协议包含多种消息，包含 `ping`,`pong`,`meet`,`fail` 等等

- 一致性 hash 算法 :

  - 一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。将哈希空间 [0, 2n-1] 看成一个哈希环，每个服务器节点都配置到哈希环上。每个数据对象通过哈希取模得到哈希值之后，存放到哈希环中顺时针方向第一个**大于等于**该哈希值的节点上
  - 一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成**缓存热点**的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡
  - redis cluster 有固定的 `16384` 个 hash slot，对每个 `key` 计算 `CRC16` 值，然后对 `16384`取模，可以获取 key 对应的 hash slot
  - redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去，任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器

- sentinel，中文名是哨兵。哨兵是 redis 集群机构中非常重要的一个组件，主要有以下功能：

  - 集群监控：负责监控 redis master 和 slave 进程是否正常工作
  - 消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员
  - 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上
  - 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址

- redis 过期策略是：**定期删除 + 惰性删除**

- redis 内存淘汰机制有以下几个：

  - noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用
  -  **allkeys-lru**：当内存不足以容纳新写入数据时，在**键空间**中，移除最近最少使用的 key（这个是**最常用**的）
  - allkeys-random：当内存不足以容纳新写入数据时，在**键空间**中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊
  - volatile-lru：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，移除最近最少使用的 key（这个一般不太合适）
  - volatile-random：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，**随机移除**某个 key
  - volatile-ttl：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，有**更早过期时间**的 key 优先移除

- redis 和 memcached 有啥区别

  - redis 支持复杂的数据结构

  - redis 支持原生集群模式 

- redis 的线程模型 : redis 内部使用文件事件处理器 `file event handler`，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，根据 socket 上的事件来选择对应的事件处理器进行处理

- 文件事件处理器的结构包含 4 个部分

  - 多个 socket
  - IO 多路复用程序
  - 文件事件分派器
  - 事件处理器（连接应答处理器、命令请求处理器、命令回复处理

- redis 分布式锁和 zk 分布式锁的对比 

  - redis 分布式锁，其实**需要自己不断去尝试获取锁**，比较消耗性能。
  - zk 分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小
  - redis 获取锁的那个客户端 出现 bug 挂了，那么只能等待超时时间之后才能释放锁，znode 就没了，此时就自动释放锁
  
- bgsave的原理是什么 : fork和cow。fork是指redis通过创建子进程来进行bgsave操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来

- 是否使用过Redis集群，集群的原理是什么

  - Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。

  - Redis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。

##### 为什么使用 nginx

- 增加 nginx-http-flv-module 后作为推流服务器推送视频和音频

- 存储终端传来的图片，方便前端展示

- nginx负载均衡的算法怎么实现的

  - 轮询 (默认) 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除

  - weight 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况

  - ip_hash 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题

  - fair (第三方) 按后端服务器的响应时间来分配请求，响应时间短的优先分配。  

  - url_hash (第三方)

- 什么是 nginx : Nginx是一个web服务器和反向代理服务器，用于`HTTP`、`HTTPS`、`SMTP`、`POP3`和`IMAP`协议
- nginx 的一些特性
  - 反向代理/L7负载均衡器
  - 嵌入式Perl解释器
  - 动态二进制升级
  - 可用于重新编写URL，具有非常好的PCRE支持
- nginx 如何处理 HTTP 请求 : `Nginx`使用反应器模式。主事件循环等待操作系统发出准备事件的信号，这样数据就可以从套接字读取，在该实例中读取到缓冲区并进行处理。单个线程可以提供数万个并发连接，`Master`进程：读取及评估配置和维持，`Worker`进程：处理请求
- 什么是 C10K 问题 : `C10K`问题是指无法同时处理大量客户端(10,000)的网络套接字

##### 为什么使用 protobuf

作为序列化层，用于加速命令在服务器之间的传输

##### 如何学习

在 github 或 programCreek 搜索别人的写法，然后模仿

  